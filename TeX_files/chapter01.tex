\chapter{特征工程}
\setlength{\parskip}{6pt}
\begin{enumerate}
	\item 特征缩放
	\begin{itemize}
		\item 线性函数归一化。它对原始数据进行线性变换，使结果映射到$[0,1]$的范围。\\
		\begin{flalign}
			X_{norm}=\frac{X-X_{min}}{X_{max}-X_{min}}
		\end{flalign}
		其中$X$为原始数据，$X_{max}, X_{min}$分别为数据最大值和最小值。
		\item 零均值归一化.它会将原始数据映射到均值为0，标准差为1的分布上。\\
		\item 实际应用中，通过梯度下降法求解的模型通常是需要归一化的，更容易通过梯度下降找到最优解。但对于决策树模型并不适用。\\
	\end{itemize}
	\item Word2Vec
	\begin{itemize}
		\item CBOW的目标是根据上下文出现的词语来预测当前词的生成概率，Skip-gram是根据当前词来预测上下文中各词的生成概率。
		\item 神经网络部分：训练权重，使得语料库中所有单词的整体生成概率最大化。
		\item 上下文-单词 矩阵
	\end{itemize}
	\item 避免过拟合的方法
	\begin{itemize}
		\item 基于模型的方法：\\
		 简化模型（将非线性转化为线性），添加约束项以缩小假设空间（L1/L2正则），集成学习，Dropout超参数
		\item 基于数据的方法：\\
		1.一定程度内的随机旋转，平移，缩放，裁剪，填充，左右翻转等。\\
		2.对图像中的像素添加噪声扰动。\\
		3.颜色变换。\\
		4.改变图像的亮度，清晰度，对比度，锐度等。\\
	\end{itemize}
\end{enumerate}
